{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In todays exercise you will make a simple feedforward neural network that can replicate the *in silico* color mixer. You will be given quite a lot of code an only have to fill in a few blanks for this notebook to work. However, the purpose of this exercise is not only getting a NN that works but for you to gain some insight into neural networks but experimenting wit varying various aspects. You can vary \n",
    "\n",
    "* The noise level in the SilicoColorMixer used to generate data\n",
    "* The input data\n",
    "  * Amount of data\n",
    "  * Different methods to pretreat data\n",
    "  * Combine data with different pretreatment in one data set\n",
    "* The Neural Network architecture\n",
    "  * Number of hidden layers\n",
    "  * Size of hidden layers\n",
    "* Evaluation method\n",
    "* Any other interesting parameter/feature that you might come up with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by getting the MLPRegressor from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "except:\n",
    "    !pip3 install scikit-learn --user --upgrade\n",
    "    from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in other packages that you (might) need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_pie_charts import make_piechart_plot\n",
    "from silico_color_mixer import SilicoColorMixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate som input data. You can generate data in various ways. You can specify color inputs that you would really like to be in the data set or do as done below - generate some random data. We generate a 400 by 4 array with random numbers between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(np.random.rand(400, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As nice trick when dealing with NN is to normalize your inputs. It is even more true in this case where our true model, the `SilicoColorMixer`, only cares about the ratio of inputs as it normalizes within. Below is a function that normalizes a color list. The `try - except` clause makes the function less sensitive to the format of the input data thus gives some flexibility during other data pretreatments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(color_list):\n",
    "    sum_list = sum(color_list)\n",
    "    try:\n",
    "        norm_list = [1. / sum_list[0] * i for i in color_list]\n",
    "    except:\n",
    "        norm_list = [1. / sum_list * i for i in color_list]\n",
    "    return norm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pretreat the data. To avoid all data being a mix of all colors, you could remove one color from each data point at random as done below. You can do this two times if you like or come up with your own way of pretreating data to get a different training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.74575245 0.1539008  0.10034676]\n",
      " [0.31613094 0.40123293 0.         0.28263612]\n",
      " [0.45779841 0.         0.24430819 0.2978934 ]\n",
      " ...\n",
      " [0.32965734 0.32836856 0.         0.3419741 ]\n",
      " [0.06534226 0.64608588 0.28857186 0.        ]\n",
      " [0.         0.51185114 0.24740503 0.24074383]]\n"
     ]
    }
   ],
   "source": [
    "for idx, line in enumerate(x):\n",
    "    line[np.random.randint(0,4)] = 0\n",
    "    x[idx] = normalize(line)\n",
    "    \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to combine two lists which have undergone different data treatment you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "z = np.array(np.random.rand(100, 4))\n",
    "xz = np.concatenate((x, z))\n",
    "print(len(xz)) # The length of the new array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a list with the colors that are generated by the inputs. Our training data consist of input and corresponding output. What type of learning is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbs = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially try using a color mixer without noise. Once you get the grasp of it, go back to here and add some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_mixer = SilicoColorMixer(noise=False)\n",
    "# data_generator_mixer = SilicoColorMixer(noise={'colors': 1, 'volume': 0.02, 'measurement': 2},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the output.\n",
    "\n",
    "Note: We use a lot of `for` loops to the point where professional programmers will likely cry out in agony, because they are slow compared to smarter ways of obtaining the same operations. We use them because they are easy to write, read, and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rand_data in x:\n",
    "    rgbs.append(data_generator_mixer.run_cuvette(rand_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(rgbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to visualize the colors in your training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd296f89be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(rgbs)\n",
    "plt.axis('off')\n",
    "data_array = np.asarray(rgbs).reshape(20, 20, 3)  # Change this as needed, 20 x 20 = 400\n",
    "plt.imshow(np.asarray(data_array, dtype=np.uint8))\n",
    "plt.imshow(np.array(data_array, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can verify that you have a good distribution of inputs.\n",
    "\n",
    "Change the format of the output from tuple to list, which is what you need to give the neural network (Programmers, look away!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbs_list = []\n",
    "for color in rgbs:\n",
    "    rgbs_list.append(list(color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to train a neural network. We are using the \"Regressor\" because we want numerical input to return numerical output. Seek out [the online documentation of MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html). Figure out what the different keywords mean and what other keywords can be specified.\n",
    "\n",
    "Below, a neural network is initialized and then trained to your data with the `fit` method. If training takes more than 15 seconds, you have overdone it in some way or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=1e-05, hidden_layer_sizes=(10, 10, 3), max_iter=4000,\n",
       "             random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpl = MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(10,10, 3), random_state=1, max_iter=4000)\n",
    "\n",
    "mpl.fit(x,rgbs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, test how well the neural network performs. Use a noiseless color mixer for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mixer = SilicoColorMixer(noise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare point by point. This can be good sometimes if you have certain points that you know your are particularly interested in. You could also have included such points in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[172.33294529 162.41316749  49.32148027]]\n",
      "(197.75, 183.0, 26.25)\n"
     ]
    }
   ],
   "source": [
    "point = [0.25, 0.25, 0., 0.5]\n",
    "print(mpl.predict([point]))\n",
    "print(test_mixer.run_cuvette(point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the performance evaluation on a larger data set and more systematically. Generate some data the way you did before. Note, that when you generate data the same way you may inadvertently sample the same subset of data that your used to train the NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(np.random.rand(100, 4))\n",
    "for idx, line in enumerate(x_test):\n",
    "    line[np.random.randint(0,4)] = 0\n",
    "    x_test[idx] = normalize(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to quantify the difference between the test_mixer and the NN is to use your good old \"score\" function. Copy it in the cell below. Note that the output from the NN will be a list. Your \"score\" function might treat lists and tuples the same (`input_color1\\[0\\]` does not care whether `input_color1` is a list or a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your \"score function here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher\n",
    "def root_sum_sqr_err(input_color1, input_color2):\n",
    "    r_color, g_color, b_color = input_color1[0], input_color1[1], input_color1[2]\n",
    "    r_color2, g_color2, b_color2 = input_color2[0], input_color2[1], input_color2[2]\n",
    "    return ((r_color-r_color2)**2 +(g_color-g_color2)**2 + (b_color-b_color2)**2)**(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the difference scores for the points in the test set and add them to a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'your_score_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-da92ab222b2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msilico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_mixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cuvette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myour_score_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilico\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Your score function here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'your_score_function' is not defined"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for x_test_point in x_test:\n",
    "    nn = mpl.predict([x_test_point])\n",
    "    silico = test_mixer.run_cuvette(x_test_point)  \n",
    "    scores.append(your_score_function(nn[0], silico))  # Your score function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher\n",
    "scores = []\n",
    "for x_test_point in x_test:\n",
    "    nn = mpl.predict([x_test_point])\n",
    "    silico = test_mixer.run_cuvette(x_test_point)  \n",
    "    scores.append(root_sum_sqr_err(nn[0], silico))  # Your score function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.49762113962989, 43.34656650785404, 39.45696974927358, 42.7497371558347, 41.02467002235461, 45.354977107736374, 58.33758097787268, 41.638889939659364, 59.152411549178375, 50.507571720415015, 50.781848740995834, 84.4613608348714, 78.28570659406577, 48.61091252827105, 46.8738995516789, 49.62005314080898, 62.97250210146109, 59.6744594073126, 44.82899490927944, 53.39708290492396, 60.73140340043197, 36.02286807839327, 64.06029518590918, 38.05096822103962, 40.25001396836263, 39.628208921561935, 87.02667996532942, 68.61626763575383, 61.512356008852336, 111.97719305218517, 30.98115218479365, 60.14321729145358, 49.41215404212223, 51.11120735727194, 44.44903679915116, 53.27037410258087, 50.17135264144479, 42.08638828780661, 55.86025450421197, 41.604562965346595, 62.1413971200365, 40.121083007937706, 43.48025995703671, 40.6266961340654, 54.81802417840723, 49.42856420013701, 26.86191632762508, 53.52825894104133, 48.500815853138945, 63.95979749454675, 48.9441072948963, 50.54944183486107, 38.645966562294475, 48.99978751735403, 42.51494978265546, 63.29055339388894, 25.50252177933629, 48.25996970204776, 60.35031924600096, 36.25229012924686, 98.74898019587435, 54.809389084705714, 68.08310761165215, 65.96157857115597, 44.33091968084845, 33.75412103874623, 55.66135057552925, 26.371895299425063, 57.49212804930685, 62.9745878494368, 58.366470857784236, 53.18200707325169, 38.20963634735441, 42.57632710191082, 39.69625467229728, 49.26916270486584, 87.04634740849886, 34.84181177095964, 52.619324059623025, 46.17228395010856, 63.702983467642426, 51.0488501034748, 53.92703275297486, 64.18022039169594, 84.06939483729795, 26.962961196619954, 45.40156138039266, 37.57963876933578, 42.59355609076288, 60.56686056853262, 68.73214376688256, 40.82350521441035, 55.22537028158466, 45.45606343060891, 48.50547881279322, 48.029838105425334, 41.66360291410344, 48.22167441301468, 51.428832449722826, 43.99653531148836]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reduce this to a few interesting numbers by calculating statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  51.52600279816135  Standard deviation:  14.820281883528743\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: \",np.mean(scores),\" Standard deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rinse and repeat.\n",
    "\n",
    "If you feel like you got this down and are up for an extra challenge, try training multiple NN at a time. They can, but do not have to, use the same training data, architecture, etc. How do the different NN compare against each other? If you do not do this extra challenge, it will NOT count against you.\n",
    "\n",
    "Once you have a good understanding and have examined how varying different parameters change the result, you are done for today. Take a moment to appreciate yourself for your efforts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
